{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<tr style=\"vertical-align: top; padding: 0; margin: 0;background-color: #ffffff\">\n",
    "        <td style=\"vertical-align: top; padding: 0; margin: 0; padding-right: 15px;\">\n",
    "    <p style=\"background: #182AEB; color:#ffffff; text-align:justify; padding: 10px 25px;\">\n",
    "        <strong style=\"font-size: 1.0em;\"><span style=\"font-size: 1.2em;\"><span style=\"color: #ffffff;\">Deep Learning </span> for Satellite Image Classification</span> (Manning Publications)<br/>by <em>Daniel Buscombe</em></strong><br/><br/>\n",
    "        <strong>> Chapter 1: Getting Started </strong><br/>\n",
    "    </p>           \n",
    "        \n",
    "<p style=\"border: 1px solid #ff5733; border-left: 15px solid #ff5733; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #ff5733\">What you will learn in this Part.</strong>  \n",
    "    <br/>In this first part we will refresh our jupyter, keras, Tensorflow 2, and git skills. These are a necessary part of your workflow and a standard collection of tools used in both industry and academia. Optionally, we will explore how to use the Sentinel API to download, display and save Sentinel-2 imagery.\n",
    "    \n",
    "   There may be places in this notebook where the code gets a difficult to understand. I encourage you not to get too bogged down in the details just yet; you will see many of these same functions again and each time I may explain a different aspect of them, and your understanding will improve as you progress through the project. Many of the details of the code are unimportant, at least initially, but are necessary to create functional example workflows that are relevant to later Parts \n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #182AEB;\">\n",
    "    </small><br/>Introduction to<br/> Jupyter notebooks</h1>\n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #182AEB; text-align:justify; padding: 0 10px;\">\n",
    "<a href=\"https://jupyter.org/\">Jupyter</a> notebooks are a way to share executable code that can be run through a web browser. \n",
    "</p>\n",
    "<p style=\"border-left: 15px solid #6019D6; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #6019D6;\">Tip.</strong> \n",
    "A notebook kernel is a computational engine that executes the code contained in a notebook. The ipython kernel executes python code. Kernels for many other languages also exist.\n",
    "</p>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use question mark in order to get help. To execute cell you have to press Shift+Enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment to see the 'full' help menu, which is a lot of output\n",
    "?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To execute the code in a particular cell, click on the cell and hit shift-enter.\n",
    "* Before you execute the code in an arbitrary cell it is good to run all the code once so that all imports and variables are initialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love Python\n"
     ]
    }
   ],
   "source": [
    "print('I love Python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [1,2,3,4,5]\n",
    "plt.plot(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question mark after a function will open pager with documentation. Double question mark will show you source code of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment to see the 'full' help menu, which is a lot of output\n",
    "plt.plot??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting text\n",
    "\n",
    "Double click on this cell to reveal the unformatted text which can then be re-executed, either from the buttons provided or by holding down shift while you press enter\n",
    "\n",
    "As you can see below, formatting text characters apply to markdown cells\n",
    "\n",
    "Emphasis, aka italics, with *asterisks* or _underscores_.\n",
    "\n",
    "Strong emphasis, aka bold, with **asterisks** or __underscores__.\n",
    "\n",
    "Combined emphasis with **asterisks and _underscores_**.\n",
    "\n",
    "Strikethrough uses two tildes. ~~Scratch this.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[I'm an inline-style link](https://www.google.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write equations inline: $e = mc^2$, $e^{i\\pi}+1=0$\n",
    "\n",
    "or in display format:\n",
    "\n",
    "$$ e^x = \\sum_{i=0}^{\\infty}\\frac{1}{i!}x^i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://python.org/images/python-logo.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='http://python.org/images/python-logo.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"400\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/F4rFuIb1Ie4\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x22878dcf2e8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('F4rFuIb1Ie4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out how long it take to run a command with %timeit magic function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.8 ms ± 1.66 ms per loop (mean ± std. dev. of 7 runs, 12 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 12 list(range(1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all interactive variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable       Type      Data/Info\n",
      "----------------------------------\n",
      "Image          type      <class 'IPython.core.display.Image'>\n",
      "YouTubeVideo   type      <class 'IPython.lib.display.YouTubeVideo'>\n",
      "plt            module    <module 'matplotlib.pyplo<...>\\\\matplotlib\\\\pyplot.py'>\n",
      "x              list      n=5\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get information about all magic functions type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## uncomment if you are interested in all the magic commands, \n",
    "## but it isn't necessary to read it to execute the rest of the notebook\n",
    "# %magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can navigate and list file contents in python using the ```os``` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\camil\\Documents\\GitHub\\DeepLearningSatelliteImage\\1_GettingStarted\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of different ways of running a python script and passing it variables. To demonstrate this, let's first make a simple script that accepts 2 variables and prints them to screen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = 50\n",
    "var2 = 'jupyter_is_cool'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```writefile``` is a so-called [magic command](https://ipython.readthedocs.io/en/stable/interactive/magics.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_script.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_script.py\n",
    "import sys\n",
    "script, var1, var2 = sys.argv\n",
    "print(\"Script name:\", script)\n",
    "print(\"First variable:\", var1)\n",
    "print(\"Second variable:\", var2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the script using the ```run``` jupyter magic command. Variables are passed to the script using a $ symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script name: ./test_script.py\n",
      "First variable: 50\n",
      "Second variable: jupyter_is_cool\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ./test_script.py $var1 $var2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... or using the bang operator. This is the convention we'll adopt in this clinic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Script name: test_script.py\n",
      "First variable: 50\n",
      "Second variable: jupyter_is_cool\n"
     ]
    }
   ],
   "source": [
    "! python test_script.py $var1 $var2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File management and resources on linux\n",
    "\n",
    "(these commands below only work in the cloud environment, unless you are in an environment supporting bash. Uncomment to run)\n",
    "\n",
    "How much memory do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat /proc/meminfo | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPUs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat /proc/cpuinfo | grep processor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storage space?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! df -h | grep \"/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #182AEB;\">\n",
    "    </small><br/>Getting started with<br/> Tensorflow 2 and Keras</h1>  \n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #182AEB; text-align:justify; padding: 0 10px;\">\n",
    "    <strong style=\"color: #182AEB;\">Intro.</strong> \n",
    "TensorFlow is a way of representing computation without actually performing it until asked. In this sense, it is a form of lazy computing, and it allows for some great improvements to the running of code:\n",
    "<ul>\n",
    "  <li>Faster computation of complex variables</li>\n",
    "  <li>Distributed computation across multiple systems, including GPUs.</li>\n",
    "  <li>Reduced redundency in some computations</li>\n",
    "</ul>\n",
    "</p>\n",
    "<p style=\"border-left: 15px solid #6019D6; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #6019D6;\">Tip.</strong> \n",
    "TensorFlow allows you to create dataflow graphs. These are structures that describe how data moves through a graph, or a series of processing nodes. Each node in the graph represents a mathematical operation, and each connection or edge between nodes is a multidimensional data array, or tensor. Keras is a set of layers that describes how to build neural networks using a clear standard. The Sequential API defines a Neural Network as a stack of layers. It very easy to define a model and to add new layers</p>\n",
    "\n",
    "<p style=\"border-left: 15px solid #4E9317; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #4E9317;\">More Resources.</strong> \n",
    "<ul>\n",
    "  <li><a href=\"https://www.tensorflow.org/tutorials\">Getting Started with Tensorflow</a></li>    \n",
    "  <li><a href=\"https://github.com/sarangzambare/segmentation\">Segmentation of cells using CNNs and TF-2</a></li>\n",
    "  <li><a href=\"https://github.com/tensorflow/models/tree/master/research/deeplab\">Segmentation Segmentation using DeepLab</a></li>\n",
    "</ul></p>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we're going to import the ```tensorflow``` module and print the version number. At the time of writing, the version number is ```2.0.0```. Be aware that it is possible this code could break with other (later/earlier) versions of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can test to see if a GPU is available like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-4094b961bc85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_gpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#tf.config.list_physical_devices('GPU')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\framework\\test_util.py\u001b[0m in \u001b[0;36mis_gpu_available\u001b[1;34m(cuda_only, min_cuda_compute_capability)\u001b[0m\n\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1432\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mlocal_device\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdevice_lib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_local_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1433\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlocal_device\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"GPU\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1434\u001b[0m         if (min_cuda_compute_capability is None or\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\client\\device_lib.py\u001b[0m in \u001b[0;36mlist_local_devices\u001b[1;34m(session_config)\u001b[0m\n\u001b[0;32m     39\u001b[0m   return [\n\u001b[0;32m     40\u001b[0m       \u001b[0m_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m       \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m   ]\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mlist_devices\u001b[1;34m(session_config)\u001b[0m\n\u001b[0;32m   2247\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mListDevicesWithSessionConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2248\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2249\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mListDevices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found."
     ]
    }
   ],
   "source": [
    "tf.test.is_gpu_available()\n",
    "#tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras\n",
    "\n",
    "A good way to get oriented with keras is to read the [summary documentation](https://keras.io/), but note that in this project you are recommended to use the version of keras within tensorflow, so the [tf.keras documentation](https://www.tensorflow.org/guide/keras) is also very relevant. Also, [this blog post](https://towardsdatascience.com/tensorflow-is-in-a-relationship-with-keras-introducing-tf-2-0-dcf1228f73ae) is worth a read, as is [this other blog post](https://www.pyimagesearch.com/2019/10/21/keras-vs-tf-keras-whats-the-difference-in-tensorflow-2-0/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two ways to make a model\n",
    "\n",
    "We're going to familiarize ourselves with tensorflow and keras using a relevant example, involving image classification. Instead of our project task involving semantic segmentation (classification of every pixel), computer scientists tend to refer to classification of whole images as 'image classification'.\n",
    "\n",
    "```keras``` is accessed as ```tf.keras``` and its layers can be imported separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow keras layers\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, we have imported 2 different types of layers (`Dense`, `Dropout`), and `Flatten` that isn't technically a layer but is classified as one because it transforms a layer's dimensions (specifically, it turns a 2D matrix into a 1D vector). We will encounter and discuss further the various layers in more depth in subsequent Parts, but `Dense` is a densely connected layer where each neuron of the previous layer connects to each neuron in the previous layer. `Dropout` is one of several strategies for preventing model overfitting. It randomly drops a certain proportion of neurons, to prevent the model 'memorizing' the data and promote model generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This a simple neural network model with one hidden layer that receives a 28 x 28 pixel image, and outputs one of 10 values. It has one hidden layer with 128 neurons and a rectified linear unit (```relu```) activation function. Between the hidden layer and output (classifying) layer there is a dropout layer where 20 % of neurons are randomly discarded. Softmax is an activation function. See [here](https://towardsdatascience.com/softmax-function-simplified-714068bf8156) for a good explanation. See [here](https://keras.io/activations/) for alternatives. It might be a good idea to play with different activation functions to explore their utility and effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "cudaGetDevice() failed. Status: cudaGetErrorString symbol not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-783374ce6749>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    194\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    815\u001b[0m           \u001b[1;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m           \u001b[1;31m# overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 817\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2139\u001b[0m         \u001b[1;31m# operations.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2140\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2141\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2142\u001b[0m       \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2143\u001b[0m       \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m   1025\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1027\u001b[1;33m         trainable=True)\n\u001b[0m\u001b[0;32m   1028\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1029\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections_arg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m         aggregation=aggregation)\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[1;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         **kwargs_for_getter)\n\u001b[0m\u001b[0;32m    745\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m     \u001b[1;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[1;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[0;32m    137\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[1;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m         shape=shape)\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m                         shape=None):\n\u001b[0;32m    196\u001b[0m     \u001b[1;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\ops\\variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[1;34m(next_creator, **kwargs)\u001b[0m\n\u001b[0;32m   2505\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2506\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2507\u001b[1;33m         shape=shape)\n\u001b[0m\u001b[0;32m   2508\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2509\u001b[0m     return variables.RefVariable(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\ops\\variables.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[0;32m   1404\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m           \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1406\u001b[1;33m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[0;32m   1407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1408\u001b[0m   def _init_from_args(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[1;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[0;32m   1535\u001b[0m           \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initializer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1536\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[1;32m-> 1537\u001b[1;33m                 \u001b[0minitial_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1538\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[0;32m   1539\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m           (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[0;32m    118\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m       \u001b[0minit_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m       \u001b[0mvariable_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, shape, dtype)\u001b[0m\n\u001b[0;32m    435\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3.0\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[0;32m    798\u001b[0m       \u001b[0mop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m     return op(\n\u001b[1;32m--> 800\u001b[1;33m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\ops\\random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[1;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[0;32m    235\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"random_uniform\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m     \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m     \u001b[0mminval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"min\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[0mmaxval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"max\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mshape_tensor\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m    962\u001b[0m       \u001b[1;31m# not convertible to Tensors becasue of mixed content.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    963\u001b[0m       \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimension_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 964\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    965\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    966\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, preferred_dtype, dtype_hint)\u001b[0m\n\u001b[0;32m   1182\u001b[0m   preferred_dtype = deprecation.deprecated_argument_lookup(\n\u001b[0;32m   1183\u001b[0m       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\n\u001b[1;32m-> 1184\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[1;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[0;32m   1240\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_hint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\u001b[0m\n\u001b[0;32m   1294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1295\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1296\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    284\u001b[0m                                          as_ref=False):\n\u001b[0;32m    285\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 286\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    225\u001b[0m   \"\"\"\n\u001b[0;32m    226\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 227\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    233\u001b[0m   \u001b[0mctx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\liveproject\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\u001b[0m in \u001b[0;36mensure_initialized\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_is_async\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mASYNC\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m           \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_ContextOptionsSetAsync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_NewContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFE_DeleteContextOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: cudaGetDevice() failed. Status: cudaGetErrorString symbol not found."
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we introduce the `Sequential` model. You should take some time to explore is numerous useful properties, such as \n",
    "\n",
    "1. `.summary()`, which shows the model architecture\n",
    "\n",
    "2. `.layers`, which lists the layers of the model and their shapes\n",
    "\n",
    "3. `.save()` saves the model in its current state of training, so you can keep a record of the state of the model at various points through training. Models can be recovered from a file using `tensorflow.keras.models.load_model()`\n",
    "\n",
    "4. `.save_weights()` saves only the weights of the model to a file\n",
    "\n",
    "5. `.inputs` and `.outputs` provide access to model inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the same as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify by comparing the two model summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use our model to classify imagery. Load the [MNIST dataset](http://yann.lecun.com/exdb/mnist/), split into test and training sets, and convert the samples from integers to floating-point numbers.\n",
    "\n",
    "The imagery data contained in the variables `x_test` and `x_train` are divided by 255.0 to normalize their values, such that all pixels have values that vary between 0 and 1, instead of 0 and 255 which is the the range of values for a standard 8-bit image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# check some statistics\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = x_train.shape[1:3]\n",
    "print(\"# of train examples:\", x_train.shape[0])\n",
    "print(\"# of test examples:\", x_test.shape[0])\n",
    "print(\"Image shape:\", x_train[0].shape)\n",
    "print(\"Pixel value interval:\", np.min(x_train), np.max(x_train))\n",
    "print(\"Train shape:\",x_train.shape)\n",
    "print(\"Test shape:\",x_test.shape)\n",
    "print(\"Image height:\",IMAGE_HEIGHT)\n",
    "print(\"Image width:\",IMAGE_WIDTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at some examples. Please remember that code such as this is provided as a succinct example workflow, but it is possible to develop similar 'solutions' on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# visualize some of the examples\n",
    "fig, axs = plt.subplots(nrows=3, ncols=6, constrained_layout=False, figsize=(12,4))\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    ax.imshow(x_train[i], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard is a tool for visualizing model training, such as how the loss function decreased, or accuracy increased, as a function of training epoch. Its use is often an essential part of optimizing model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%reload_ext tensorboard\n",
    "\n",
    "# create the tensorboard callback\n",
    "tensorboard = TensorBoard(log_dir='logs', histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling `.compile()` is a required step before model training. The following must be specified:\n",
    "\n",
    "1. `optimizer` that performs the gradient descent (numerical solver)\n",
    "\n",
    "2. `loss` that is the metric to be optimized. Below we choose `sparse_categorical_crossentropy` because we have a categorical problem (hence `categorical_crossentropy`) that is not [one-hot-encoded](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/) (hence `sparse`)\n",
    "\n",
    "3. `metrics`, which are additional metrics to evaluate during training  but, unlike loss, are not used in the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launch tensorboard for visualizing model training. You should see graphs `epoch_accuracy` and `epoch_loss` that show accuracy and loss function value, respectively, as a function of training epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch TensorBoard from Jupyter\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the built-in ```evaluate``` function to see overall classification loss (first number) and accuracy (second number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image classifier is now trained to ~98% accuracy on this dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Confusion Matrix\n",
    "A ‘confusion matrix’, which is the matrix of normalized correspondences between true and estimated labels, is a convenient way to visualize model skill. \n",
    "\n",
    "A perfect correspondence between true and estimated labels is scored 1.0 along the diagonal elements of the matrix.\n",
    "\n",
    "Misclassiﬁcations are readily identiﬁed as off-diagonal elements. Systematic misclassiﬁcations are recognized as off-diagonal elements with large magnitudes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is long and might be difficult to follow in parts. This is a good time to remind you that that's ok; you will see this function again, and it isn't crucial to any workflow you will develop. It serves only to exemplify and guide, and many the details of many of the long functions such as these are largely unimportant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    \n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the built-in ```predict``` function to create a vector of predicted classes for each input in the ```x_test``` set. These values are one-hot encoded, which means we recover the most likely class using the ```argmax``` function (i.e. the location in the vector, ```predictions```, of the maximum value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your model using the test data\n",
    "predictions = model.predict(x_test)\n",
    "predictions = tf.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the confusion matrix\n",
    "classes=['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "plot_confusion_matrix(y_test, predictions, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above demonstration shows that for relatively simple classification tasks (i.e. recognizing handwritten digits) doesn't necessarily require deep learning. Our network was small, consisting of only one hidden layer. In the next task we will be using much bigger, more powerful networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "<p style=\"border: 1px solid #ff5733; border-left: 15px solid #ff5733; padding: 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #ff5733\">Deliverable</strong>  \n",
    "    <br/>The deliverable for Part 1 is a jupyter notebook showing an example image(s) of a satellite dataset read in using rasterio, and demonstration of a function that carries out a manipulation of that image using keras and Tensorflow 2.0. That manipulation could be anything that alters the image, such as its size, geometry (shape), pixel intensities, or spatial projection. This will mostly test your understanding of keras syntax, which is an essential component of the remaining Parts. You may find the <a href=\"https://www.tensorflow.org/api_docs/python/tf/image\">tensorflow-image</a> library helpful.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"font-size: 1em; padding: 0; margin: 0;\">\n",
    "\n",
    "<h1 style=\"width: 100%; text-align: left; padding: 0px 25px;\"><small style=\"color: #182AEB;\">\n",
    "    </small><br/>Going further: <br/> Introduction to satellite imagery</h1>  \n",
    "<br/>\n",
    "<p style=\"border-left: 15px solid #182AEB; text-align:justify; padding: 0 10px;\">\n",
    "    <strong style=\"color: #182AEB;\">Intro.</strong>\n",
    "    The <a href=\"https://sentinels.copernicus.eu/\">Sentinel satellites</a> are part of Europe’s <a href=\"http://copernicus.eu/\">Copernicus </a> programme (formerly known as Global Monitoring for Environment and Security (GMES)). The overall mission is composed of five constellations of satellites. The Sentinel-2 mission consists of two satellites with a multi-spectral instrument for monitoring agriculture, vegetation and forests, land cover change, coastal zones, inland water monitoring, glaciers, ice extent and snow cover.\n",
    "</p>\n",
    "<p style=\"border-left: 15px solid #6019D6; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #6019D6;\">Tip.</strong> \n",
    "    A comprehensive introduction to the mission and its data can be found <a href=\"https://eox.at/2015/12/understanding-sentinel-2-satellite-data/\"> here</a>. Your starting point for all data services is <a href=\"https://www.sentinel-hub.com/sentinel-2\">Sentinel Hub </a></p>\n",
    "\n",
    "<p style=\"border-left: 15px solid #4E9317; padding: 0 10px; text-align:justify;\">\n",
    "    <strong style=\"color: #4E9317;\">More Resources.</strong> \n",
    "<ul>\n",
    "  <li><a href=\"https://krstn.eu/download-Sentinel-2-images/\">Another guide to using sentinselsat</a></li>    \n",
    "  <li><a href=\"https://automating-gis-processes.github.io/CSC18/lessons/L6/raster-mosaic.html\">Using rasterio</a></li>\n",
    "</ul>\n",
    "        </tr>\n",
    "        </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing a satellite image using rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download a sample Sentinel-2 JP2 (JPEG2000) file from google drive\n",
    "\n",
    "The details of this function are unimportant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/38511444/python-download-files-from-google-drive-using-url\n",
    "import requests\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_id = '1o76QoBtn6ExxO8KgcCqdOiun_KsWoMJl'\n",
    "destination = 'example_TCI_10m.jp2'\n",
    "download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read first band of the jp2 file into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open('example_TCI_10m.jp2', driver='JP2OpenJPEG') as dataset:\n",
    "    array = dataset.read(1)\n",
    "    print(dataset.profile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count = 3 means there are three bands in the raster:\n",
    "\n",
    "* Band 1 - the blue band\n",
    "* Band 2 - the green band\n",
    "* Band 3 - the red band\n",
    "\n",
    "A few more jp2 images can be downloaded using the following file id: 1o76QoBtn6ExxO8KgcCqdOiun_KsWoMJl. This is a zipped folder 120 MB in size containing several images of the area around Lake Poopó, Bolivia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing a satellite image to geotiff using rasterio\n",
    "\n",
    "The following function takes a JP2 image, an output file name (with tiff extension) and a single band number (1, 2, or 3) and writes the raster to the new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_image(input, output, band):\n",
    "    with rasterio.open(input) as src_dataset:\n",
    "        with rasterio.open('example_TCI_10m.jp2', driver='JP2OpenJPEG') as dataset:\n",
    "            array = dataset.read(band)\n",
    "        # Get a copy of the source dataset's profile. Thus our\n",
    "        # destination dataset will have the same dimensions,\n",
    "        # number of bands, data type, and georeferencing as the\n",
    "        # source dataset.\n",
    "        kwds = src_dataset.profile\n",
    "\n",
    "        # Change the format driver for the destination dataset to\n",
    "        # 'GTiff', short for GeoTIFF.\n",
    "        kwds['driver'] = 'GTiff'\n",
    "\n",
    "        # Add GeoTIFF-specific keyword arguments.\n",
    "        kwds['tiled'] = True\n",
    "        kwds['blockxsize'] = 256\n",
    "        kwds['blockysize'] = 256\n",
    "        kwds['photometric'] = 'YCbCr'\n",
    "        kwds['compress'] = 'JPEG'\n",
    "\n",
    "        with rasterio.open(output, 'w', **kwds) as dst_dataset:\n",
    "            # Write data to the destination dataset.\n",
    "            dst_dataset.write(array.astype(rasterio.uint8), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of files we will create, each with a 1-band raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['r1.tif', 'r2.tif', 'r3.tif']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use list comprehension to call the ```write_image``` function for all 3 bands in turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[write_image('example_TCI_10m.jp2',f, band) for f,band in zip(file_list, [1,2,3])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next bit of code gets the meta data from the first file (that is the same as the remaining two files), and writes a merged 3-band raster in geoTIFF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read metadata of first file\n",
    "with rasterio.open(file_list[0]) as src0:\n",
    "    meta = src0.meta\n",
    "\n",
    "# Update meta to reflect the number of layers\n",
    "meta.update(count = len(file_list))\n",
    "\n",
    "# Read each layer and write it to stack\n",
    "with rasterio.open('stack.tif', 'w', **meta) as dst:\n",
    "    for id, layer in enumerate(file_list, start=1):\n",
    "        with rasterio.open(layer) as src1:\n",
    "            dst.write_band(id, src1.read(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now done with the three intermediate files, so we can delete them to save space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[os.remove(f) for f in file_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the new meta data that shows the Coordinate Reference System or CRS. The EPSG code is 32719"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image spatial projections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we're going to reproject our raster so it is in a different spatial projection. This involves specifying a new CRS (this time we use EPSG code 4326)\n",
    "\n",
    "Example modified from https://rasterio.readthedocs.io/en/stable/topics/reproject.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import some utility functions from rasterio that will create and apply the transformation. Again we use a nested 'with statement' to first read in the raster to be projected (```stack.tif```) and then write out the reprojected raster (```reprojected_stack.tif```)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "dst_crs = 'EPSG:4326'\n",
    "\n",
    "# note there is a nested 'with statement' here\n",
    "# the first 'with' command opens the image as src\n",
    "with rasterio.open('stack.tif') as src:\n",
    "    transform, width, height = calculate_default_transform(\n",
    "        src.crs, dst_crs, src.width, src.height, *src.bounds)\n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "# the second 'with' statement opens an image for writing\n",
    "    with rasterio.open('reprojected_stack.tif', 'w', **kwargs) as dst:\n",
    "        for i in range(1, src.count + 1):\n",
    "            reproject(\n",
    "                source=rasterio.band(src, i),\n",
    "                destination=rasterio.band(dst, i),\n",
    "                src_transform=src.transform,\n",
    "                src_crs=src.crs,\n",
    "                dst_transform=transform,\n",
    "                dst_crs=dst_crs,\n",
    "                resampling=Resampling.nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
